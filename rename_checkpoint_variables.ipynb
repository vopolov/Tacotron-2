{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from tensorflow.contrib.framework import list_variables, load_variable\n",
    "\n",
    "from tacotron.models import Tacotron\n",
    "from hparams import hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'logs-Tacotron/taco_pretrained_r9y9'\n",
    "assert os.path.isdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 190/190 [00:21<00:00,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs-Tacotron/taco_pretrained_r9y9\\model.ckpt-189500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# source : https://gist.github.com/batzner/7c24802dd9c5e15870b4b56e22135c96\n",
    "\n",
    "checkpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "\n",
    "dry_run = False\n",
    "\n",
    "variables = list_variables(checkpoint_dir)\n",
    "\n",
    "with tf.Session() as sess, tqdm.tqdm(total=len(variables)) as pbar:\n",
    "    for var_name, _ in list_variables(checkpoint_dir):\n",
    "        # Load the variable\n",
    "        var = load_variable(checkpoint_dir, var_name)\n",
    "\n",
    "        # Set the new name\n",
    "        new_name = var_name\n",
    "\n",
    "        new_name = new_name.replace('model', 'Tacotron_model')\n",
    "        new_name = new_name.replace('attention_variable', 'attention_variable_projection')\n",
    "        for i in range(hparams.decoder_layers):\n",
    "            new_name = new_name.replace(f'decoder_lstm/multi_rnn_cell/cell_{i}/ZoneoutLSTMCell/Linear/Bias',\n",
    "                                        f'decoder_LSTM/multi_rnn_cell/cell_{i}/decoder_LSTM_{i+1}/bias')\n",
    "            new_name = new_name.replace(f'decoder_lstm/multi_rnn_cell/cell_{i}/ZoneoutLSTMCell/Linear/Matrix',\n",
    "                                        f'decoder_LSTM/multi_rnn_cell/cell_{i}/decoder_LSTM_{i+1}/kernel')\n",
    "        new_name = new_name.replace('linear_transform', 'linear_transform_projection')\n",
    "        for d in ('fw', 'bw'):\n",
    "            new_name = new_name.replace(f'encoder_LSTM/bidirectional_rnn/{d}/ZoneoutLSTMCell/Linear/Bias',\n",
    "                                        f'encoder_LSTM/bidirectional_rnn/{d}/encoder_{d}_LSTM/bias')\n",
    "            new_name = new_name.replace(f'encoder_LSTM/bidirectional_rnn/{d}/ZoneoutLSTMCell/Linear/Matrix',\n",
    "                                        f'encoder_LSTM/bidirectional_rnn/{d}/encoder_{d}_LSTM/kernel')\n",
    "            \n",
    "        if dry_run:\n",
    "#             print('%s would be renamed to %s' % (var_name, new_name))\n",
    "            pass\n",
    "        else:\n",
    "#             print('Renaming %s to %s' % (var_name, new_name))\n",
    "            # Rename the variable\n",
    "            var = tf.Variable(var, name=new_name)\n",
    "            \n",
    "        pbar.update(1)\n",
    "\n",
    "    if not dry_run:\n",
    "        # Save the variables\n",
    "        saver = tf.train.Saver()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        new_checkpoint_path = saver.save(sess, checkpoint.model_checkpoint_path)\n",
    "        \n",
    "#         *previous, last_step = checkpoint.model_checkpoint_path.split('-')\n",
    "#         last_step = str(int(last_step) + 1)\n",
    "#         new_checkpoint_path = '-'.join((*previous, last_step))\n",
    "        \n",
    "#         old_files = glob.glob(new_checkpoint_path + '*')\n",
    "#         for f in old_files:\n",
    "#             os.remove(f)\n",
    "        \n",
    "#         new_checkpoint_path = saver.save(sess, new_checkpoint_path)\n",
    "\n",
    "print(new_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables = list_variables(os.path.dirname(new_checkpoint_path))\n",
    "# for v, _ in variables:\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialisation done /gpu:0\n",
      "Initialized Tacotron model. Dimensions (? = dynamic shape): \n",
      "  Train mode:               False\n",
      "  Eval mode:                False\n",
      "  GTA mode:                 False\n",
      "  Synthesis mode:           True\n",
      "  Input:                    (?, ?)\n",
      "  device:                   0\n",
      "  embedding:                (?, ?, 512)\n",
      "  enc conv out:             (?, ?, 512)\n",
      "  encoder out:              (?, ?, 512)\n",
      "  decoder out:              (?, ?, 80)\n",
      "  residual out:             (?, ?, 512)\n",
      "  projected residual out:   (?, ?, 80)\n",
      "  mel out:                  (?, ?, 80)\n",
      "  <stop_token> out:         (?, ?)\n",
      "  Tacotron Parameters       108.945 Million.\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.int32, (None, None), name='inputs')\n",
    "input_lengths = tf.placeholder(tf.int32, (None), name='input_lengths')\n",
    "# targets = tf.placeholder(tf.float32, (None, None, hparams.num_mels), name='mel_targets')\n",
    "split_infos = tf.placeholder(tf.int32, shape=(hparams.tacotron_num_gpus, None), name='split_infos')\n",
    "with tf.variable_scope('Tacotron_model', reuse=tf.AUTO_REUSE) as scope:\n",
    "    model = Tacotron(hparams)\n",
    "    model.initialize(inputs, input_lengths, split_infos=split_infos)\n",
    "    \n",
    "    variables = tf.trainable_variables()\n",
    "    \n",
    "#     for v in variables:\n",
    "#         print(v.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
